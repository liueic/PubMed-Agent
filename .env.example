# ============================================
# PubMed Agent 环境配置文件
# ============================================
# 复制此文件为 .env 并填入您的实际配置值
# Copy this file to .env and fill in your actual configuration values

# ============================================
# LLM 大模型配置 (支持多种供应商 / Multi-Provider Support)
# ============================================
# 通用配置（推荐使用，支持所有兼容 OpenAI API 的模型）
# General Configuration (Recommended, supports all OpenAI-compatible APIs)

# LLM API 密钥 - 支持多种供应商
# LLM API Key - Supports multiple providers
# - OpenAI: 从 https://platform.openai.com/api-keys 获取
# - Azure OpenAI: 使用 Azure 门户中的密钥
# - 本地模型/代理: 使用代理服务的 API Key
# - 其他兼容 OpenAI API 的供应商
LLM_API_KEY=your_api_key_here

# 向后兼容：如果未设置 LLM_API_KEY，可以使用 OPENAI_API_KEY
# Backward Compatibility: If LLM_API_KEY is not set, OPENAI_API_KEY will be used
# OPENAI_API_KEY=your_openai_api_key_here

# LLM Base URL - 自定义 API 端点（可选）
# LLM Base URL - Custom API endpoint (Optional)
# 如果为空，则使用默认 OpenAI URL: https://api.openai.com/v1
# If empty, uses default OpenAI URL: https://api.openai.com/v1
#
# 示例 (Examples):
# - Azure OpenAI: https://your-resource.openai.azure.com/
# - 本地模型/代理: http://localhost:8000/v1
# - LM Studio: http://localhost:1234/v1
# - Anthropic (通过代理): https://api.anthropic.com/v1
# - 其他兼容服务: https://your-api-endpoint.com/v1
LLM_BASE_URL=

# LLM 模型名称 - 用户可自由填写
# LLM Model Name - User can freely specify
# 
# OpenAI 模型示例 (OpenAI Models):
# - gpt-4o: 最新最强模型，适合复杂推理
# - gpt-4o-mini: 性价比高，适合一般查询
# - gpt-4-turbo: 高性能模型
# - gpt-3.5-turbo: 经济实惠，适合简单查询
#
# Azure OpenAI 示例 (Azure OpenAI Examples):
# - gpt-4: 标准 GPT-4 模型
# - gpt-35-turbo: Azure 部署的 GPT-3.5
#
# 本地模型示例 (Local Model Examples):
# - llama-2-7b-chat: 本地部署的 LLaMA 2
# - mistral-7b-instruct: Mistral 模型
# - 其他兼容 OpenAI API 格式的模型名称
LLM_MODEL=gpt-4o

# 向后兼容：如果未设置 LLM_MODEL，可以使用 OPENAI_MODEL
# Backward Compatibility: If LLM_MODEL is not set, OPENAI_MODEL will be used
# OPENAI_MODEL=gpt-4o

# ============================================
# LLM 推理参数 (LLM Reasoning Parameters)
# ============================================
# 温度参数 (Temperature)
# 0.0: 确定性回答，适合科学查询 (Deterministic, good for scientific queries)
# 0.7: 默认值，平衡创造性和准确性 (Default, balanced creativity and accuracy)
# 0.1-0.3: 略微创造性 (Slightly creative)
# 0.7-1.0: 更创造性 (More creative)
TEMPERATURE=0.7

# Top-P 参数 (Nucleus Sampling)
# 0.95: 默认值，适合大多数模型 (Default, good for most models)
# 0.1-0.9: 更保守的采样 (More conservative sampling)
# 0.9-1.0: 更开放的采样 (More open sampling)
TOP_P=0.95

# ============================================
# 嵌入模型配置 (Embedding Model Configuration)
# ============================================
# 支持独立供应商配置，默认与 LLM 供应商一致
# Supports independent provider configuration, defaults to LLM provider

# Embedding API 密钥 (可选)
# Embedding API Key (Optional)
# 如果未填写，则使用 LLM_API_KEY（与 LLM 供应商一致）
# If not set, uses LLM_API_KEY (same as LLM provider)
# 
# 使用场景 (Use Cases):
# - 默认情况: 留空，自动使用 LLM_API_KEY
# - 独立供应商: 填写独立的 API Key（如使用不同的 OpenAI 账户）
# - 本地模型 (LM Studio): 可以填写任意值（如 "lm-studio"），因为本地模型通常不需要验证
#   Local Model (LM Studio): Can fill in any value (e.g., "lm-studio"), as local models usually don't require authentication
EMBEDDING_API_KEY=

# Embedding Base URL (可选)
# Embedding Base URL (Optional)
# 如果未填写，则使用 LLM_BASE_URL（与 LLM 供应商一致）
# If not set, uses LLM_BASE_URL (same as LLM provider)
#
# 使用场景 (Use Cases):
# - 默认情况: 留空，自动使用 LLM_BASE_URL
# - 本地模型 (LM Studio): http://localhost:1234/v1
# - Azure OpenAI: https://your-resource.openai.azure.com/
# - 其他兼容服务: https://your-api-endpoint.com/v1
#
# 示例配置 (Example Configurations):
# - LM Studio 本地模型: EMBEDDING_BASE_URL=http://localhost:1234/v1
# - 与 LLM 使用相同服务: 留空即可
EMBEDDING_BASE_URL=

# 嵌入模型名称 - 用户可自由填写
# Embedding Model Name - User can freely specify
# 
# OpenAI 模型示例 (OpenAI Models):
# - text-embedding-3-small: 小型高效模型 (Small and efficient)
# - text-embedding-3-large: 大型高精度模型 (Large and high precision)
# - text-embedding-ada-002: 经典模型 (Classic model)
#
# 本地模型示例 (Local Model Examples):
# - 使用 LM Studio 或其他本地服务时，填写模型名称
# - When using LM Studio or other local services, specify the model name
# - 例如: all-MiniLM-L6-v2, bge-large-en-v1.5 等
EMBEDDING_MODEL=text-embedding-3-small

# 嵌入向量维度 (Embedding Dimension)
# text-embedding-3-small: 1536 (默认)
# text-embedding-3-large: 3072
# text-embedding-ada-002: 1536
EMBEDDING_DIMENSION=1536

# ============================================
# 向量数据库配置 (Vector Database Configuration)
# ============================================
# 向量数据库类型: "chroma" 或 "faiss"
# Vector Database Type: "chroma" or "faiss"
VECTOR_DB_TYPE=chroma

# ChromaDB 持久化目录 (ChromaDB Persist Directory)
CHROMA_PERSIST_DIRECTORY=./data/chroma

# FAISS 索引文件路径 (FAISS Index File Path)
FAISS_INDEX_PATH=./data/faiss.index

# ============================================
# PubMed API 配置 (PubMed API Configuration)
# ============================================
# PubMed 邮箱 (推荐填写，用于 API 限流识别)
# PubMed Email (Recommended, for API rate limiting identification)
PUBMED_EMAIL=your_email@example.com

# PubMed 工具名称 (PubMed Tool Name)
PUBMED_TOOL_NAME=pubmed_agent

# PubMed API 密钥 (可选，用于提高 API 限制)
# PubMed API Key (Optional, for higher API limits)
PUBMED_API_KEY=

# ============================================
# 检索和分块配置 (Retrieval and Chunking Configuration)
# ============================================
# 最大检索结果数 (Maximum Retrieve Results)
MAX_RETRIEVE_RESULTS=10

# 文本分块大小 (Text Chunk Size)
CHUNK_SIZE=1000

# 文本分块重叠大小 (Text Chunk Overlap)
CHUNK_OVERLAP=200

# ============================================
# 日志配置 (Logging Configuration)
# ============================================
# 日志级别: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Log Level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ============================================
# 使用说明 (Usage Instructions)
# ============================================
# 1. 复制此文件: copy .env.example .env (Windows) 或 cp .env.example .env (Linux/macOS)
# 2. 编辑 .env 文件，填入您的实际配置值
# 3. 确保 LLM_API_KEY 或 OPENAI_API_KEY 已正确设置
# 4. 根据需要调整其他配置项
#
# 多模型供应商支持 (Multi-Provider Support):
# - OpenAI: 设置 LLM_API_KEY，LLM_MODEL，LLM_BASE_URL 留空
# - Azure OpenAI: 设置 LLM_API_KEY，LLM_BASE_URL 为 Azure 端点，LLM_MODEL 为部署名称
# - 本地模型 (LM Studio): 设置 LLM_BASE_URL=http://localhost:1234/v1，LLM_MODEL 为模型名称
# - 其他兼容服务: 设置 LLM_BASE_URL 和 LLM_API_KEY
#
# Embedding 配置说明 (Embedding Configuration):
# - 默认情况: EMBEDDING_API_KEY 和 EMBEDDING_BASE_URL 留空，自动使用 LLM 的配置
# - 独立配置: 填写 EMBEDDING_API_KEY 和 EMBEDDING_BASE_URL，使用独立的 embedding 服务
# - 本地模型 (LM Studio): EMBEDDING_BASE_URL=http://localhost:1234/v1，EMBEDDING_API_KEY 可填写任意值
#
# 1. Copy this file: copy .env.example .env (Windows) or cp .env.example .env (Linux/macOS)
# 2. Edit .env file and fill in your actual configuration values
# 3. Make sure LLM_API_KEY or OPENAI_API_KEY is correctly set
# 4. Adjust other configuration items as needed
